{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZu-7QbP9muh"
      },
      "source": [
        "DSML investigation:\n",
        "\n",
        "You are part of the Suisse Impossible Mission Force, or SIMF for short. You need to uncover a rogue agent that is trying to steal sensitive information.\n",
        "\n",
        "Your mission, should you choose to accept it, is to find that agent before stealing any classified information. Good luck!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DyL7WNdV9sWV"
      },
      "source": [
        "# Assignement part four\n",
        "#### Identifying the suspects' credit score\n",
        "We received informations that the rogue agent has a good credit score.\n",
        "\n",
        "Our spies at SIMF have managed to collect financial information relating to our suspects as well as a training dataset.\n",
        "\n",
        "Create a Neural Network over the training dataset `df` to identify which of the suspects have a good Credit_Mix\n",
        "\n",
        "\n",
        "## Getting to know our data\n",
        "\n",
        "* Age: a users age\n",
        "* Occupation: a users employment field\n",
        "* Annual_Income: a users annual income\n",
        "* Monthly_Inh_Salary: the calculated salary received by a given user on a monthly basis\n",
        "* Num_Bank_Accounts: the number of bank accounts possessed by a given user\n",
        "* Num_Credit_Cards: the number of credit card given user possesses\n",
        "* Interest_Rate: The interest rate on those cards (if multiple then its the average)\n",
        "* Num_of_Loans: The number of loans of each user\n",
        "* Delay_from_due_date: payment tardiness of user\n",
        "* Num_of_Delayed_Payment: the count of delayed payments\n",
        "* Changed_Credit_Limit: changes made to the credit limit for each user's account\n",
        "* Num_Credit_Inquiries: number of credit inquiries\n",
        "* Credit_Mix: The users credit score\n",
        "* Outsting_Debt: Outstanding debt\n",
        "* Credit_Utilization_Ratio: the percentage of borrowed money over borrowing allowance\n",
        "* Payment_of_Min_Amount: does the user usually pay the minimal amount (categorical)\n",
        "* Total_EMI_per_month: Monthly repayments to be made\n",
        "* Amount_invested_monthly: The amout put in an investment fund by the user on a monthly basis\n",
        "* Payment_Behaviour: the users payment behavior (categorical)\n",
        "* Monthly_Balance: The users end of the month balance\n",
        "* AutoLoan: If the user has an active loan for their vehicule\n",
        "* Credit-BuilderLoan: If the user has a loan to increase their credit score\n",
        "* DebtConsolidationLoan, HomeEquityLoan, MortgageLoan, NotSpecified, PaydayLoan, PersonalLoan, StudentLoan: different types of loans(categorical features)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "XHhI95r5-tyD"
      },
      "outputs": [],
      "source": [
        "# Import required packages\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "FXm79UyPF1Bz"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"https://raw.githubusercontent.com/michalis0/MGT-502-Data-Science-and-Machine-Learning/main/data/train_classification.csv\", index_col='Unnamed: 0').dropna()\n",
        "suspects = pd.read_csv(\"https://raw.githubusercontent.com/michalis0/MGT-502-Data-Science-and-Machine-Learning/main/data/suspects.csv\", index_col='Unnamed: 0').dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "GHi25uhvF1Bz",
        "outputId": "a1f28f3f-8d71-487d-e81d-ca229a6c14d7"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-08b60fa1-dddf-4f78-adf6-26ec27507db5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>Occupation</th>\n",
              "      <th>Annual_Income</th>\n",
              "      <th>Monthly_Inh_Salary</th>\n",
              "      <th>Num_Bank_Accounts</th>\n",
              "      <th>Num_Credit_Card</th>\n",
              "      <th>Interest_Rate</th>\n",
              "      <th>Num_of_Loan</th>\n",
              "      <th>Delay_from_due_date</th>\n",
              "      <th>Num_of_Delayed_Payment</th>\n",
              "      <th>...</th>\n",
              "      <th>Monthly_Balance</th>\n",
              "      <th>AutoLoan</th>\n",
              "      <th>Credit-BuilderLoan</th>\n",
              "      <th>DebtConsolidationLoan</th>\n",
              "      <th>HomeEquityLoan</th>\n",
              "      <th>MortgageLoan</th>\n",
              "      <th>NotSpecified</th>\n",
              "      <th>PaydayLoan</th>\n",
              "      <th>PersonalLoan</th>\n",
              "      <th>StudentLoan</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>23</td>\n",
              "      <td>Scientist</td>\n",
              "      <td>19114.12</td>\n",
              "      <td>1824.843333</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>...</td>\n",
              "      <td>186.266702</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>24</td>\n",
              "      <td>Scientist</td>\n",
              "      <td>19114.12</td>\n",
              "      <td>1824.843333</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>9</td>\n",
              "      <td>...</td>\n",
              "      <td>361.444004</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>24</td>\n",
              "      <td>Scientist</td>\n",
              "      <td>19114.12</td>\n",
              "      <td>4182.004291</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>...</td>\n",
              "      <td>343.826873</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>28</td>\n",
              "      <td>Teacher</td>\n",
              "      <td>34847.84</td>\n",
              "      <td>3037.986667</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>...</td>\n",
              "      <td>303.355083</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>35</td>\n",
              "      <td>Engineer</td>\n",
              "      <td>143162.64</td>\n",
              "      <td>4182.004291</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>1942</td>\n",
              "      <td>...</td>\n",
              "      <td>854.226027</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 29 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-08b60fa1-dddf-4f78-adf6-26ec27507db5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-08b60fa1-dddf-4f78-adf6-26ec27507db5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-08b60fa1-dddf-4f78-adf6-26ec27507db5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b6bcec7f-fbb7-4ce9-9124-25bd60d2b39a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b6bcec7f-fbb7-4ce9-9124-25bd60d2b39a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b6bcec7f-fbb7-4ce9-9124-25bd60d2b39a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "   Age Occupation  Annual_Income  Monthly_Inh_Salary  Num_Bank_Accounts  \\\n",
              "0   23  Scientist       19114.12         1824.843333                  3   \n",
              "1   24  Scientist       19114.12         1824.843333                  3   \n",
              "3   24  Scientist       19114.12         4182.004291                  3   \n",
              "5   28    Teacher       34847.84         3037.986667                  2   \n",
              "8   35   Engineer      143162.64         4182.004291                  1   \n",
              "\n",
              "   Num_Credit_Card  Interest_Rate  Num_of_Loan  Delay_from_due_date  \\\n",
              "0                4              3            4                    3   \n",
              "1                4              3            4                    3   \n",
              "3                4              3            4                    4   \n",
              "5                4              6            1                    3   \n",
              "8                5              8            3                    8   \n",
              "\n",
              "   Num_of_Delayed_Payment  ...  Monthly_Balance  AutoLoan Credit-BuilderLoan  \\\n",
              "0                       7  ...       186.266702         1                  1   \n",
              "1                       9  ...       361.444004         1                  1   \n",
              "3                       5  ...       343.826873         1                  1   \n",
              "5                       3  ...       303.355083         0                  1   \n",
              "8                    1942  ...       854.226027         2                  0   \n",
              "\n",
              "   DebtConsolidationLoan  HomeEquityLoan MortgageLoan  NotSpecified  \\\n",
              "0                      0               1            0             0   \n",
              "1                      0               1            0             0   \n",
              "3                      0               1            0             0   \n",
              "5                      0               0            0             0   \n",
              "8                      0               0            0             1   \n",
              "\n",
              "   PaydayLoan PersonalLoan  StudentLoan  \n",
              "0           0            1            0  \n",
              "1           0            1            0  \n",
              "3           0            1            0  \n",
              "5           0            0            0  \n",
              "8           0            0            0  \n",
              "\n",
              "[5 rows x 29 columns]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "suspects.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "CRYOzdc65mgB",
        "outputId": "745d0254-1786-47eb-a750-54379875abc8"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Age  Annual_Income  Monthly_Inh_Salary  Num_Bank_Accounts  \\\n",
              "0  23.0       19114.12         1824.843333                3.0   \n",
              "1  24.0       19114.12         1824.843333                3.0   \n",
              "3  24.0       19114.12         4182.004291                3.0   \n",
              "5  28.0       34847.84         3037.986667                2.0   \n",
              "8  35.0      143162.64         4182.004291                1.0   \n",
              "\n",
              "   Num_Credit_Card  Interest_Rate  Num_of_Loan  Delay_from_due_date  \\\n",
              "0              4.0            3.0          4.0                  3.0   \n",
              "1              4.0            3.0          4.0                  3.0   \n",
              "3              4.0            3.0          4.0                  4.0   \n",
              "5              4.0            6.0          1.0                  3.0   \n",
              "8              5.0            8.0          3.0                  8.0   \n",
              "\n",
              "   Num_of_Delayed_Payment  Changed_Credit_Limit  ...  Occupation_Journalist  \\\n",
              "0                     7.0                 11.27  ...                    0.0   \n",
              "1                     9.0                 13.27  ...                    0.0   \n",
              "3                     5.0                 11.27  ...                    0.0   \n",
              "5                     3.0                  5.42  ...                    0.0   \n",
              "8                  1942.0                  7.10  ...                    0.0   \n",
              "\n",
              "   Occupation_Lawyer  Occupation_Manager  Occupation_Mechanic  \\\n",
              "0                0.0                 0.0                  0.0   \n",
              "1                0.0                 0.0                  0.0   \n",
              "3                0.0                 0.0                  0.0   \n",
              "5                0.0                 0.0                  0.0   \n",
              "8                0.0                 0.0                  0.0   \n",
              "\n",
              "   Occupation_MediaManager  Occupation_Musician  Occupation_Scientist  \\\n",
              "0                      0.0                  0.0                   1.0   \n",
              "1                      0.0                  0.0                   1.0   \n",
              "3                      0.0                  0.0                   0.0   \n",
              "5                      0.0                  0.0                   0.0   \n",
              "8                      0.0                  0.0                   0.0   \n",
              "\n",
              "   Occupation_Teacher  Occupation_Writer  userID  \n",
              "0                 0.0                0.0  317991  \n",
              "1                 0.0                0.0  241892  \n",
              "3                 1.0                0.0  303376  \n",
              "5                 0.0                0.0  761992  \n",
              "8                 0.0                0.0  373318  \n",
              "\n",
              "[5 rows x 43 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-de0568e7-1ff9-4290-b32f-c73f200c2f61\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>Annual_Income</th>\n",
              "      <th>Monthly_Inh_Salary</th>\n",
              "      <th>Num_Bank_Accounts</th>\n",
              "      <th>Num_Credit_Card</th>\n",
              "      <th>Interest_Rate</th>\n",
              "      <th>Num_of_Loan</th>\n",
              "      <th>Delay_from_due_date</th>\n",
              "      <th>Num_of_Delayed_Payment</th>\n",
              "      <th>Changed_Credit_Limit</th>\n",
              "      <th>...</th>\n",
              "      <th>Occupation_Journalist</th>\n",
              "      <th>Occupation_Lawyer</th>\n",
              "      <th>Occupation_Manager</th>\n",
              "      <th>Occupation_Mechanic</th>\n",
              "      <th>Occupation_MediaManager</th>\n",
              "      <th>Occupation_Musician</th>\n",
              "      <th>Occupation_Scientist</th>\n",
              "      <th>Occupation_Teacher</th>\n",
              "      <th>Occupation_Writer</th>\n",
              "      <th>userID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>23.0</td>\n",
              "      <td>19114.12</td>\n",
              "      <td>1824.843333</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>11.27</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>317991</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>24.0</td>\n",
              "      <td>19114.12</td>\n",
              "      <td>1824.843333</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>13.27</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>241892</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>24.0</td>\n",
              "      <td>19114.12</td>\n",
              "      <td>4182.004291</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>11.27</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>303376</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>28.0</td>\n",
              "      <td>34847.84</td>\n",
              "      <td>3037.986667</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.42</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>761992</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>35.0</td>\n",
              "      <td>143162.64</td>\n",
              "      <td>4182.004291</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>1942.0</td>\n",
              "      <td>7.10</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>373318</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 43 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-de0568e7-1ff9-4290-b32f-c73f200c2f61')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-de0568e7-1ff9-4290-b32f-c73f200c2f61 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-de0568e7-1ff9-4290-b32f-c73f200c2f61');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c9a18c25-9ad8-40cf-b495-e33a23886e35\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c9a18c25-9ad8-40cf-b495-e33a23886e35')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c9a18c25-9ad8-40cf-b495-e33a23886e35 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "suspects"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lpZT59dqF1B0",
        "outputId": "27c799e2-6284-48d2-b6a3-7ac9d5d9938e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['Good', 'Standard', 'Bad'], dtype=object)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df[\"Credit_Mix\"].unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZENObtyefVk"
      },
      "source": [
        "# 1. Preparing the data\n",
        "## 1.1 Data cleaning\n",
        " Perform One-Hot Encoding over the \"Occupation\" feature.\n",
        "\n",
        " Then, perform Label Encoding over \"Payment_of_Min_Amount\" and \"Payment_Behaviour\".\n",
        "\n",
        " After performing the one-hot and label encoding, add the encoded features to the data frame and remove the corresponding categorical features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "JGVrLNJTefVk"
      },
      "outputs": [],
      "source": [
        "# Your code here:\n",
        "# Initialize\n",
        "\n",
        "#Apply one-hot encoding to nominal variables\n",
        "ohe = OneHotEncoder(sparse_output = False).set_output(transform = 'pandas')\n",
        "\n",
        "# Apply label encoding to ordinal variables\n",
        "le = LabelEncoder()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "TXUjOhUkTkUr"
      },
      "outputs": [],
      "source": [
        "## Apply\n",
        "\n",
        "# label\n",
        "df['Payment_of_Min_Amount'] = le.fit_transform(df['Payment_of_Min_Amount'])\n",
        "df['Payment_Behaviour'] = le.fit_transform(df['Payment_Behaviour'])\n",
        "\n",
        "## one-hot\n",
        "# transform\n",
        "occupation_transformed = ohe.fit_transform(df[['Occupation']])\n",
        "\n",
        "# concat with original df and drop original columns\n",
        "df_new = pd.concat([df, occupation_transformed], axis = 1).drop(columns = 'Occupation')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# on the suspects dataset\n"
      ],
      "metadata": {
        "id": "6UOx_73K5g2o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfPnhUxAefVl"
      },
      "source": [
        "## 1.2 Dataset splitting and rescaling\n",
        "\n",
        "a) Split the dataset in two, first X with your independent features and then y with the dependent feature **CreditMix**.\n",
        "\n",
        "b) Split X and y into training and test sets. The training set should contain 80% of the observations, and the test set should contain the remaining 20%. Set random state equal to 42.\n",
        "\n",
        "c) Then perform :\n",
        "* Label Encoding over the **CreditMix** feature.\n",
        "* A MinMaxScaller over all the independent features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "J-mentarefVm"
      },
      "outputs": [],
      "source": [
        "# Your code here\n",
        "X = df_new.drop(columns = 'Credit_Mix')\n",
        "y = pd.DataFrame(df_new['Credit_Mix'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "zSEAkcvmU6TF"
      },
      "outputs": [],
      "source": [
        "# Split\n",
        "random_seed = 42\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = random_seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "n9zgYiibdirW"
      },
      "outputs": [],
      "source": [
        "X_train = pd.DataFrame(X_train)\n",
        "X_test = pd.DataFrame(X_test)\n",
        "y_train = pd.DataFrame(y_train)\n",
        "y_test = pd.DataFrame(y_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "mjSQRr1QVI09"
      },
      "outputs": [],
      "source": [
        "# Scale\n",
        "y_train['Credit_Mix'] = le.fit_transform(y_train['Credit_Mix'])\n",
        "y_test['Credit_Mix'] = le.transform(y_test['Credit_Mix'])\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# on the whole dataset\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "y_scaled = y.copy()\n",
        "y_scaled['Credit_Mix'] = le.fit_transform(y['Credit_Mix'])\n",
        "\n",
        "X_scaled_torch = torch.tensor(X_scaled, dtype=torch.float)\n",
        "y_scaled_torch = torch.tensor(y_scaled.values.squeeze(), dtype=torch.long)\n"
      ],
      "metadata": {
        "id": "dfDUtIIK63g4"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmjXsvhKF1B3"
      },
      "source": [
        "### 1.2.2 Final touches\n",
        "Convert your datasets to `Torch tensors` of type `torch.float` for X and `torch.long` for y."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "2KS_U8stefVo"
      },
      "outputs": [],
      "source": [
        "#Your code here:\n",
        "X_train = torch.tensor(X_train, dtype=torch.float)\n",
        "y_train = torch.tensor(y_train.values.squeeze(), dtype=torch.long)\n",
        "X_test = torch.tensor(X_test, dtype=torch.float)\n",
        "y_test = torch.tensor(y_test.values.squeeze(), dtype=torch.long)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNOpO2ZnvTk_",
        "outputId": "a2ba1c55-6e8d-478b-8db5-6d46ac4920cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([23378, 42]) torch.Size([23378])\n"
          ]
        }
      ],
      "source": [
        "print(X_train.size(), y_train.size())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(suspects.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W34r2cjh_8Ai",
        "outputId": "53d02737-e1b9-4058-c261-75b66ac3a0a2"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(714, 43)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(le.classes_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XyLyntDq8U_u",
        "outputId": "37b55925-1c38-4f27-ec8a-8a7cad473ac7"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Bad' 'Good' 'Standard']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NpJNiQADF1B3"
      },
      "source": [
        "# 2 Model preparation:\n",
        "\n",
        "## 2.1 Define a Neural network model and instantiate it.\n",
        "Set the following parameters:\n",
        "* `hidden layer` : 1 with 150 nurons;\n",
        "* `activation function` : ReLU\n",
        "* `criterion` : [CrossEntropyLoss](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "cx-3yvp5efVp"
      },
      "outputs": [],
      "source": [
        "# Define the neural network class\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, D_in, H1, D_out):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        self.linear1 = nn.Linear(D_in, H1)        # Linear transformation for hidden layer\n",
        "        self.linear2 = nn.Linear(H1, D_out)       # Linear transformation for output layer\n",
        "        self.activation = nn.ReLU()               # Activation function for hidden layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        y_pred = self.activation(self.linear1(x))   # Hidden layer: linear transformation + ReLU\n",
        "        y_pred = self.linear2(y_pred)               # Output layer: linear transformation\n",
        "        return y_pred\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "euL8SMialbyd"
      },
      "outputs": [],
      "source": [
        "D_in = X_train.shape[1]\n",
        "D_out = torch.unique(y_train).numel()\n",
        "H1 = 150"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "498y5CrHldO8"
      },
      "outputs": [],
      "source": [
        "# Model with 150 neurons\n",
        "model1 = Net(D_in, H1, D_out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "dEFB3oqClpKJ"
      },
      "outputs": [],
      "source": [
        "# CEL loss\n",
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bnfvHbEF1B4"
      },
      "source": [
        "## 2.2 Finding the best model:\n",
        "Identify, amongst the following options the best parameters for your model:\n",
        "\n",
        "* `criterion` : [CrossEntropyLoss](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html)\n",
        "* `iterations` : 150, 250, 500, 1000\n",
        "* `learning rate` : 0.00005, 0.001, 1.049, 12.031\n",
        "\n",
        "Set `random seed` as torch.manual_seed(42).\n",
        "\n",
        "\n",
        "_Hint: restart your runtime between each execution to ensure that previous neural networks dont interfere with your current one_\n",
        "\n",
        "_You can evaluate your model based on it's accuracy over the test set_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cjc_J2vXnkR0"
      },
      "outputs": [],
      "source": [
        "# SGD optimizer for finding the weights of the network\n",
        "optimizer = torch.optim.SGD(model1.parameters(), lr=1e-4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "CthlCvtl0lXk",
        "outputId": "c440b3b6-e1aa-4973-8e3c-f4c4eec9c3da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epochs: 150, Learning Rate: 5e-05, Accuracy: 0.4545765611633875\n",
            "Epochs: 150, Learning Rate: 0.001, Accuracy: 0.788366124893071\n",
            "Epochs: 150, Learning Rate: 1.049, Accuracy: 0.857656116338751\n",
            "Epochs: 150, Learning Rate: 12.031, Accuracy: 0.2309666381522669\n",
            "Epochs: 250, Learning Rate: 5e-05, Accuracy: 0.4545765611633875\n",
            "Epochs: 250, Learning Rate: 0.001, Accuracy: 0.808896492728828\n",
            "Epochs: 250, Learning Rate: 1.049, Accuracy: 0.8388366124893071\n",
            "Epochs: 250, Learning Rate: 12.031, Accuracy: 0.4545765611633875\n",
            "Epochs: 500, Learning Rate: 5e-05, Accuracy: 0.5538066723695466\n",
            "Epochs: 500, Learning Rate: 0.001, Accuracy: 0.8335329341317366\n",
            "Epochs: 500, Learning Rate: 1.049, Accuracy: 0.8391787852865698\n",
            "Epochs: 500, Learning Rate: 12.031, Accuracy: 0.4545765611633875\n",
            "Epochs: 1000, Learning Rate: 5e-05, Accuracy: 0.7375534644995723\n",
            "Epochs: 1000, Learning Rate: 0.001, Accuracy: 0.839863130881095\n",
            "Epochs: 1000, Learning Rate: 1.049, Accuracy: 0.8696321642429427\n",
            "Epochs: 1000, Learning Rate: 12.031, Accuracy: 0.2309666381522669\n",
            "Best Accuracy: 0.8696321642429427\n",
            "Best Parameters: {'epochs': 1000, 'learning_rate': 1.049}\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# Set a random seed for reproducibility\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Assuming the network 'Net' and datasets 'X_train_tensor', 'y_train_tensor', 'X_test_tensor', 'y_test_tensor' are already defined\n",
        "\n",
        "# Define configurations for experiments\n",
        "iterations_options = [150, 250, 500, 1000]\n",
        "learning_rates = [0.00005, 0.001, 1.049, 12.031]\n",
        "\n",
        "# Results storage\n",
        "best_accuracy = 0\n",
        "best_params = {}\n",
        "\n",
        "# Define the dataset and data loader\n",
        "train_dataset = TensorDataset(X_train, y_train)\n",
        "test_dataset = TensorDataset(X_test, y_test)\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "# Loop over the configurations\n",
        "for epochs in iterations_options:\n",
        "    for lr in learning_rates:\n",
        "        # Define the model\n",
        "        model = Net(D_in, H1, D_out)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        optimizer = optim.SGD(model.parameters(), lr=lr)\n",
        "\n",
        "        # Training process\n",
        "        for epoch in range(epochs):\n",
        "            model.train()\n",
        "            for data, target in train_loader:\n",
        "                optimizer.zero_grad()\n",
        "                output = model(data)\n",
        "                loss = criterion(output, target)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "        # Evaluation process\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for data, target in test_loader:\n",
        "                outputs = model(data)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += target.size(0)\n",
        "                correct += (predicted == target).sum().item()\n",
        "\n",
        "        accuracy = correct / total\n",
        "        print(f'Epochs: {epochs}, Learning Rate: {lr}, Accuracy: {accuracy}')\n",
        "\n",
        "        # Update the best model\n",
        "        if accuracy > best_accuracy:\n",
        "            best_accuracy = accuracy\n",
        "            best_params = {'epochs': epochs, 'learning_rate': lr}\n",
        "\n",
        "# Print the best model's parameters and accuracy\n",
        "print(f'Best Accuracy: {best_accuracy}')\n",
        "print(f'Best Parameters: {best_params}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVn0_N37Lg2c"
      },
      "source": [
        "*Question 1:*\n",
        "\n",
        "**Could we use BCELoss instead of CrossEntropyLoss?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pMa1WScWF1B8"
      },
      "source": [
        "# 3. Predict over the suspects dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qxz8kefSHAqT"
      },
      "source": [
        "Now it's time to use the model to make predictions over the suspect dataset!\n",
        "\n",
        "Use the following parameters:\n",
        "\n",
        "\n",
        "* `hidden layer` : 1 with 150 neurons\n",
        "* `output layer` : 3 neurons\n",
        "* `optimizer` : [Stochastic Gradient Descent (SGD)](https://en.wikipedia.org/wiki/Stochastic_gradient_descent)\n",
        "* `criterion` : [CrossEntropyLoss](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html)\n",
        "* `iterations` : 1000\n",
        "* `learning rate` : 1.049\n",
        "\n",
        "Set `random seed` as np.random.seed(42)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8diIPbsLrh9"
      },
      "source": [
        "*Question 2:*\n",
        "\n",
        "**Why does our model has 3 neurons in the output layer?**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# scaling on the whole dataset\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "y_scaled = y.copy()\n",
        "y_scaled['Credit_Mix'] = le.fit_transform(y['Credit_Mix'])\n",
        "\n",
        "X_scaled_torch = torch.tensor(X_scaled, dtype=torch.float)\n",
        "y_scaled_torch = torch.tensor(y_scaled.values.squeeze(), dtype=torch.long)\n",
        "\n",
        "suspects_new = suspects.drop(columns = ['userID'])\n",
        "suspects_new = suspects_new.drop(columns = ['Predicted_Class'])\n",
        "\n",
        "suspects_new = pd.DataFrame(suspects_new)\n",
        "suspects_new_scaled = scaler.transform(suspects_new)\n",
        "suspects_new_np = suspects_new_scaled.astype('float32')  # Ensuring the data type is float32\n",
        "\n",
        "# Convert numpy array to tensor\n",
        "suspects_new_tensor = torch.tensor(suspects_new_np)\n",
        "\n"
      ],
      "metadata": {
        "id": "2XISSP2490_Q"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "FkiXBxN1LCvP",
        "outputId": "fdc5d757-2abd-49a1-eceb-76be52ed9b71"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'numpy.ndarray' object has no attribute 'head'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-aca90abd1dc3>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_scaled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'head'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "suspects_new.head()"
      ],
      "metadata": {
        "id": "J1K77rqTArwm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kHwplnc1JECi",
        "outputId": "505d1a46-fb9c-4814-c647-0741f423730f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 1.1188501119613647\n",
            "1 1.0518863201141357\n",
            "2 1.0303517580032349\n",
            "3 1.012447476387024\n",
            "4 0.9934573769569397\n",
            "5 0.9718789458274841\n",
            "6 0.9472166895866394\n",
            "7 0.9194234013557434\n",
            "8 0.8888954520225525\n",
            "9 0.8563928604125977\n",
            "10 0.8230143785476685\n",
            "11 0.7899256348609924\n",
            "12 0.7581902742385864\n",
            "13 0.728546142578125\n",
            "14 0.7014028429985046\n",
            "15 0.6769676804542542\n",
            "16 0.655630350112915\n",
            "17 0.640725314617157\n",
            "18 0.6608588099479675\n",
            "19 0.9400292634963989\n",
            "20 2.1192266941070557\n",
            "21 1.6618412733078003\n",
            "22 1.112278938293457\n",
            "23 0.9833551645278931\n",
            "24 0.8517116904258728\n",
            "25 0.8055447936058044\n",
            "26 0.7747761607170105\n",
            "27 0.7461743950843811\n",
            "28 0.7257595658302307\n",
            "29 0.7044364213943481\n",
            "30 0.7045038938522339\n",
            "31 0.7053259015083313\n",
            "32 0.7892308831214905\n",
            "33 0.7752671241760254\n",
            "34 0.9487839937210083\n",
            "35 0.6574645042419434\n",
            "36 0.6592939496040344\n",
            "37 0.6310534477233887\n",
            "38 0.6697141528129578\n",
            "39 0.653014600276947\n",
            "40 0.7528970837593079\n",
            "41 0.6604349613189697\n",
            "42 0.7517648339271545\n",
            "43 0.6197376847267151\n",
            "44 0.6611361503601074\n",
            "45 0.5980193614959717\n",
            "46 0.6354329586029053\n",
            "47 0.5967567563056946\n",
            "48 0.6417351365089417\n",
            "49 0.5991045236587524\n",
            "50 0.6429429054260254\n",
            "51 0.5865326523780823\n",
            "52 0.6190928220748901\n",
            "53 0.567099928855896\n",
            "54 0.5929318070411682\n",
            "55 0.5528284311294556\n",
            "56 0.5773934125900269\n",
            "57 0.5439228415489197\n",
            "58 0.5681460499763489\n",
            "59 0.5363904237747192\n",
            "60 0.5586013793945312\n",
            "61 0.527620255947113\n",
            "62 0.5463430881500244\n",
            "63 0.5185394287109375\n",
            "64 0.5348076820373535\n",
            "65 0.5143322944641113\n",
            "66 0.5315368175506592\n",
            "67 0.5244522094726562\n",
            "68 0.5391730666160583\n",
            "69 0.54835444688797\n",
            "70 0.5309881567955017\n",
            "71 0.5338670611381531\n",
            "72 0.49401944875717163\n",
            "73 0.4878389537334442\n",
            "74 0.4661748707294464\n",
            "75 0.4635285437107086\n",
            "76 0.4533196687698364\n",
            "77 0.4538218677043915\n",
            "78 0.448212206363678\n",
            "79 0.4532923698425293\n",
            "80 0.4525138735771179\n",
            "81 0.47050872445106506\n",
            "82 0.48634541034698486\n",
            "83 0.5437591075897217\n",
            "84 0.6101837754249573\n",
            "85 0.6748104691505432\n",
            "86 0.6231651902198792\n",
            "87 0.4958474040031433\n",
            "88 0.444254070520401\n",
            "89 0.4336542785167694\n",
            "90 0.4288564920425415\n",
            "91 0.42644378542900085\n",
            "92 0.42504072189331055\n",
            "93 0.42440909147262573\n",
            "94 0.4249343276023865\n",
            "95 0.426333487033844\n",
            "96 0.42959606647491455\n",
            "97 0.4347045421600342\n",
            "98 0.4429587721824646\n",
            "99 0.45553386211395264\n",
            "100 0.4700949192047119\n",
            "101 0.4934436082839966\n",
            "102 0.5038440823554993\n",
            "103 0.528424859046936\n",
            "104 0.5065455436706543\n",
            "105 0.5110056400299072\n",
            "106 0.47178417444229126\n",
            "107 0.46447739005088806\n",
            "108 0.44214022159576416\n",
            "109 0.43585076928138733\n",
            "110 0.42558178305625916\n",
            "111 0.4217612147331238\n",
            "112 0.4164520800113678\n",
            "113 0.41420456767082214\n",
            "114 0.41113972663879395\n",
            "115 0.4098661541938782\n",
            "116 0.40791618824005127\n",
            "117 0.4072727859020233\n",
            "118 0.40593844652175903\n",
            "119 0.4058806896209717\n",
            "120 0.40496936440467834\n",
            "121 0.40558215975761414\n",
            "122 0.40504252910614014\n",
            "123 0.40640789270401\n",
            "124 0.40609562397003174\n",
            "125 0.40842124819755554\n",
            "126 0.4082304537296295\n",
            "127 0.41173672676086426\n",
            "128 0.4112093448638916\n",
            "129 0.41578245162963867\n",
            "130 0.41432347893714905\n",
            "131 0.4194612205028534\n",
            "132 0.4162827432155609\n",
            "133 0.4212077260017395\n",
            "134 0.41598981618881226\n",
            "135 0.41973721981048584\n",
            "136 0.41315269470214844\n",
            "137 0.41547322273254395\n",
            "138 0.40889522433280945\n",
            "139 0.41027095913887024\n",
            "140 0.40484553575515747\n",
            "141 0.40605244040489197\n",
            "142 0.40264561772346497\n",
            "143 0.4046720266342163\n",
            "144 0.4059653580188751\n",
            "145 0.41048842668533325\n",
            "146 0.42585813999176025\n",
            "147 0.430826872587204\n",
            "148 0.47149452567100525\n",
            "149 0.46650558710098267\n",
            "150 0.535388171672821\n",
            "151 0.5166312456130981\n",
            "152 0.5604856014251709\n",
            "153 0.5322925448417664\n",
            "154 0.44878053665161133\n",
            "155 0.41098180413246155\n",
            "156 0.39593490958213806\n",
            "157 0.38984978199005127\n",
            "158 0.3868986964225769\n",
            "159 0.38475704193115234\n",
            "160 0.38298994302749634\n",
            "161 0.38146910071372986\n",
            "162 0.380169153213501\n",
            "163 0.37899255752563477\n",
            "164 0.3779231905937195\n",
            "165 0.3769327402114868\n",
            "166 0.37604689598083496\n",
            "167 0.37521207332611084\n",
            "168 0.3744550943374634\n",
            "169 0.3737282156944275\n",
            "170 0.37307009100914\n",
            "171 0.37244585156440735\n",
            "172 0.3719054162502289\n",
            "173 0.3713797330856323\n",
            "174 0.370962917804718\n",
            "175 0.3705504536628723\n",
            "176 0.3702949583530426\n",
            "177 0.37003293633461\n",
            "178 0.3700687289237976\n",
            "179 0.3700351119041443\n",
            "180 0.3704907298088074\n",
            "181 0.3707140386104584\n",
            "182 0.3717084527015686\n",
            "183 0.3722478151321411\n",
            "184 0.37400534749031067\n",
            "185 0.3749629259109497\n",
            "186 0.37784144282341003\n",
            "187 0.3792606294155121\n",
            "188 0.38365739583969116\n",
            "189 0.3861226737499237\n",
            "190 0.39297059178352356\n",
            "191 0.3980926275253296\n",
            "192 0.4082445204257965\n",
            "193 0.42023760080337524\n",
            "194 0.42905834317207336\n",
            "195 0.44568896293640137\n",
            "196 0.4304058253765106\n",
            "197 0.42615339159965515\n",
            "198 0.3995526432991028\n",
            "199 0.38820579648017883\n",
            "200 0.37704798579216003\n",
            "201 0.3720417022705078\n",
            "202 0.36874881386756897\n",
            "203 0.3666275441646576\n",
            "204 0.365301251411438\n",
            "205 0.36418601870536804\n",
            "206 0.3634883761405945\n",
            "207 0.3628208637237549\n",
            "208 0.36262068152427673\n",
            "209 0.3624211251735687\n",
            "210 0.36301565170288086\n",
            "211 0.36354878544807434\n",
            "212 0.3660970628261566\n",
            "213 0.3672160804271698\n",
            "214 0.3724480867385864\n",
            "215 0.373081773519516\n",
            "216 0.38069239258766174\n",
            "217 0.3778039515018463\n",
            "218 0.38466277718544006\n",
            "219 0.37671732902526855\n",
            "220 0.3795003592967987\n",
            "221 0.37095189094543457\n",
            "222 0.3713383972644806\n",
            "223 0.3657709062099457\n",
            "224 0.3660354018211365\n",
            "225 0.363086462020874\n",
            "226 0.3640650808811188\n",
            "227 0.3623291254043579\n",
            "228 0.36388543248176575\n",
            "229 0.36280718445777893\n",
            "230 0.3652137219905853\n",
            "231 0.3643975555896759\n",
            "232 0.36781662702560425\n",
            "233 0.3668612241744995\n",
            "234 0.3710656762123108\n",
            "235 0.3694634735584259\n",
            "236 0.3736858665943146\n",
            "237 0.37114959955215454\n",
            "238 0.3746602535247803\n",
            "239 0.37148556113243103\n",
            "240 0.37369704246520996\n",
            "241 0.37064313888549805\n",
            "242 0.3721157908439636\n",
            "243 0.36939579248428345\n",
            "244 0.37019458413124084\n",
            "245 0.36805301904678345\n",
            "246 0.3687158524990082\n",
            "247 0.3670194149017334\n",
            "248 0.36774569749832153\n",
            "249 0.36619308590888977\n",
            "250 0.3669789731502533\n",
            "251 0.3654484748840332\n",
            "252 0.36639782786369324\n",
            "253 0.3647453784942627\n",
            "254 0.36597150564193726\n",
            "255 0.364108145236969\n",
            "256 0.36558377742767334\n",
            "257 0.3634180426597595\n",
            "258 0.36488229036331177\n",
            "259 0.3626132309436798\n",
            "260 0.36423155665397644\n",
            "261 0.3617820143699646\n",
            "262 0.3633304536342621\n",
            "263 0.36078375577926636\n",
            "264 0.36227697134017944\n",
            "265 0.35977625846862793\n",
            "266 0.36117294430732727\n",
            "267 0.3588387370109558\n",
            "268 0.36019596457481384\n",
            "269 0.35807812213897705\n",
            "270 0.35947346687316895\n",
            "271 0.3575471341609955\n",
            "272 0.35905003547668457\n",
            "273 0.35724008083343506\n",
            "274 0.3588657081127167\n",
            "275 0.3570835590362549\n",
            "276 0.3587651550769806\n",
            "277 0.3569301664829254\n",
            "278 0.3585968315601349\n",
            "279 0.3567660450935364\n",
            "280 0.3584021031856537\n",
            "281 0.3566563129425049\n",
            "282 0.3584152162075043\n",
            "283 0.35659265518188477\n",
            "284 0.3582717478275299\n",
            "285 0.3565232455730438\n",
            "286 0.3583025336265564\n",
            "287 0.3565000295639038\n",
            "288 0.3581583797931671\n",
            "289 0.3564760684967041\n",
            "290 0.3582945764064789\n",
            "291 0.35656270384788513\n",
            "292 0.3582807183265686\n",
            "293 0.35665443539619446\n",
            "294 0.3584388792514801\n",
            "295 0.35685062408447266\n",
            "296 0.35859158635139465\n",
            "297 0.35710617899894714\n",
            "298 0.3588975965976715\n",
            "299 0.3574180603027344\n",
            "300 0.3590754568576813\n",
            "301 0.35776329040527344\n",
            "302 0.3594967722892761\n",
            "303 0.3581656813621521\n",
            "304 0.359764039516449\n",
            "305 0.3584975302219391\n",
            "306 0.35996773838996887\n",
            "307 0.3587687313556671\n",
            "308 0.36012396216392517\n",
            "309 0.358997642993927\n",
            "310 0.36017054319381714\n",
            "311 0.35907408595085144\n",
            "312 0.3600422739982605\n",
            "313 0.3590141832828522\n",
            "314 0.3598598539829254\n",
            "315 0.3588568866252899\n",
            "316 0.3595860004425049\n",
            "317 0.35851407051086426\n",
            "318 0.3591247498989105\n",
            "319 0.3580177128314972\n",
            "320 0.3585718870162964\n",
            "321 0.3574084937572479\n",
            "322 0.35797590017318726\n",
            "323 0.35669583082199097\n",
            "324 0.3572843670845032\n",
            "325 0.355973482131958\n",
            "326 0.356624573469162\n",
            "327 0.35522228479385376\n",
            "328 0.35596081614494324\n",
            "329 0.3545021414756775\n",
            "330 0.35529908537864685\n",
            "331 0.35382020473480225\n",
            "332 0.35469383001327515\n",
            "333 0.3531591594219208\n",
            "334 0.3540784418582916\n",
            "335 0.352552592754364\n",
            "336 0.35352665185928345\n",
            "337 0.35205262899398804\n",
            "338 0.3531237840652466\n",
            "339 0.3516232967376709\n",
            "340 0.35270488262176514\n",
            "341 0.35122933983802795\n",
            "342 0.35236987471580505\n",
            "343 0.3508929908275604\n",
            "344 0.3520188629627228\n",
            "345 0.35060954093933105\n",
            "346 0.35178038477897644\n",
            "347 0.3503413796424866\n",
            "348 0.3514232635498047\n",
            "349 0.3500838279724121\n",
            "350 0.35126447677612305\n",
            "351 0.3498697578907013\n",
            "352 0.35096475481987\n",
            "353 0.3495810627937317\n",
            "354 0.35063397884368896\n",
            "355 0.3493083417415619\n",
            "356 0.35036802291870117\n",
            "357 0.34907105565071106\n",
            "358 0.35010090470314026\n",
            "359 0.3488008379936218\n",
            "360 0.349752813577652\n",
            "361 0.3485473096370697\n",
            "362 0.34954625368118286\n",
            "363 0.34833824634552\n",
            "364 0.34927496314048767\n",
            "365 0.34815579652786255\n",
            "366 0.3491666316986084\n",
            "367 0.3480757474899292\n",
            "368 0.34908589720726013\n",
            "369 0.3480212986469269\n",
            "370 0.34908565878868103\n",
            "371 0.34804412722587585\n",
            "372 0.34915632009506226\n",
            "373 0.34813395142555237\n",
            "374 0.3493330478668213\n",
            "375 0.34834933280944824\n",
            "376 0.3496149182319641\n",
            "377 0.3486931622028351\n",
            "378 0.3500917851924896\n",
            "379 0.34924599528312683\n",
            "380 0.35080385208129883\n",
            "381 0.3500624895095825\n",
            "382 0.35176387429237366\n",
            "383 0.35113948583602905\n",
            "384 0.35303381085395813\n",
            "385 0.35246285796165466\n",
            "386 0.35432493686676025\n",
            "387 0.3538597524166107\n",
            "388 0.35565322637557983\n",
            "389 0.35535839200019836\n",
            "390 0.3568789064884186\n",
            "391 0.35680121183395386\n",
            "392 0.3580051362514496\n",
            "393 0.3581923246383667\n",
            "394 0.359022855758667\n",
            "395 0.35958096385002136\n",
            "396 0.3601740598678589\n",
            "397 0.36148497462272644\n",
            "398 0.36218246817588806\n",
            "399 0.36489516496658325\n",
            "400 0.36542001366615295\n",
            "401 0.3693569600582123\n",
            "402 0.3675922751426697\n",
            "403 0.37047675251960754\n",
            "404 0.3661596179008484\n",
            "405 0.3663068413734436\n",
            "406 0.3619636297225952\n",
            "407 0.3613584339618683\n",
            "408 0.35786688327789307\n",
            "409 0.35711973905563354\n",
            "410 0.3546045124530792\n",
            "411 0.35402753949165344\n",
            "412 0.35231974720954895\n",
            "413 0.35200735926628113\n",
            "414 0.35068464279174805\n",
            "415 0.35049721598625183\n",
            "416 0.3494654595851898\n",
            "417 0.3494105637073517\n",
            "418 0.3485625088214874\n",
            "419 0.34869006276130676\n",
            "420 0.3479810953140259\n",
            "421 0.34834763407707214\n",
            "422 0.34768685698509216\n",
            "423 0.3483330309391022\n",
            "424 0.34747084975242615\n",
            "425 0.3482520878314972\n",
            "426 0.3471192419528961\n",
            "427 0.3477296829223633\n",
            "428 0.34653496742248535\n",
            "429 0.34721964597702026\n",
            "430 0.34600964188575745\n",
            "431 0.34671905636787415\n",
            "432 0.34557172656059265\n",
            "433 0.3464045226573944\n",
            "434 0.3453083038330078\n",
            "435 0.34628167748451233\n",
            "436 0.3452262580394745\n",
            "437 0.3464047312736511\n",
            "438 0.3453625738620758\n",
            "439 0.3466913402080536\n",
            "440 0.3456006348133087\n",
            "441 0.34699246287345886\n",
            "442 0.34585040807724\n",
            "443 0.34730616211891174\n",
            "444 0.34613651037216187\n",
            "445 0.347556471824646\n",
            "446 0.3464202582836151\n",
            "447 0.3478080630302429\n",
            "448 0.346670925617218\n",
            "449 0.34791868925094604\n",
            "450 0.34685465693473816\n",
            "451 0.34801116585731506\n",
            "452 0.3469800055027008\n",
            "453 0.3480057716369629\n",
            "454 0.34700554609298706\n",
            "455 0.34791818261146545\n",
            "456 0.3469628691673279\n",
            "457 0.34775516390800476\n",
            "458 0.3468155562877655\n",
            "459 0.34754228591918945\n",
            "460 0.3466009199619293\n",
            "461 0.3472287356853485\n",
            "462 0.34632208943367004\n",
            "463 0.34689050912857056\n",
            "464 0.34598347544670105\n",
            "465 0.34646815061569214\n",
            "466 0.3456195890903473\n",
            "467 0.34608224034309387\n",
            "468 0.3452809751033783\n",
            "469 0.34575554728507996\n",
            "470 0.34497153759002686\n",
            "471 0.3454529643058777\n",
            "472 0.3446653485298157\n",
            "473 0.3451700210571289\n",
            "474 0.3443838655948639\n",
            "475 0.34490352869033813\n",
            "476 0.34410572052001953\n",
            "477 0.3446460962295532\n",
            "478 0.343862384557724\n",
            "479 0.3444509208202362\n",
            "480 0.3436284065246582\n",
            "481 0.3442087471485138\n",
            "482 0.3433806896209717\n",
            "483 0.34397774934768677\n",
            "484 0.3431639075279236\n",
            "485 0.34382179379463196\n",
            "486 0.3429810404777527\n",
            "487 0.34366413950920105\n",
            "488 0.3427877724170685\n",
            "489 0.3435174822807312\n",
            "490 0.3425871729850769\n",
            "491 0.3433503210544586\n",
            "492 0.3423289358615875\n",
            "493 0.34303778409957886\n",
            "494 0.34202495217323303\n",
            "495 0.3426962196826935\n",
            "496 0.34178492426872253\n",
            "497 0.3425067365169525\n",
            "498 0.34161046147346497\n",
            "499 0.3423471748828888\n",
            "500 0.3414454460144043\n",
            "501 0.34218883514404297\n",
            "502 0.3412785232067108\n",
            "503 0.3419729173183441\n",
            "504 0.3411060571670532\n",
            "505 0.3418000638484955\n",
            "506 0.34094682335853577\n",
            "507 0.34161147475242615\n",
            "508 0.3408099412918091\n",
            "509 0.34150636196136475\n",
            "510 0.34071290493011475\n",
            "511 0.3414185643196106\n",
            "512 0.34063026309013367\n",
            "513 0.3413376808166504\n",
            "514 0.34054532647132874\n",
            "515 0.34124115109443665\n",
            "516 0.34045735001564026\n",
            "517 0.3411549925804138\n",
            "518 0.34036144614219666\n",
            "519 0.3410404920578003\n",
            "520 0.3402448296546936\n",
            "521 0.34090545773506165\n",
            "522 0.34013402462005615\n",
            "523 0.3407992720603943\n",
            "524 0.34004896879196167\n",
            "525 0.34070906043052673\n",
            "526 0.33998197317123413\n",
            "527 0.34064534306526184\n",
            "528 0.3399263620376587\n",
            "529 0.34059029817581177\n",
            "530 0.339888334274292\n",
            "531 0.34056001901626587\n",
            "532 0.33988890051841736\n",
            "533 0.3405844271183014\n",
            "534 0.33990949392318726\n",
            "535 0.3406095504760742\n",
            "536 0.3399418294429779\n",
            "537 0.3406587243080139\n",
            "538 0.3400224447250366\n",
            "539 0.3407209515571594\n",
            "540 0.34016314148902893\n",
            "541 0.340920627117157\n",
            "542 0.34045037627220154\n",
            "543 0.34128668904304504\n",
            "544 0.3408912718296051\n",
            "545 0.3417990207672119\n",
            "546 0.34156733751296997\n",
            "547 0.3426411747932434\n",
            "548 0.34266197681427\n",
            "549 0.34400856494903564\n",
            "550 0.3443584442138672\n",
            "551 0.346104234457016\n",
            "552 0.34685495495796204\n",
            "553 0.3491763174533844\n",
            "554 0.3504652976989746\n",
            "555 0.35349059104919434\n",
            "556 0.3551501929759979\n",
            "557 0.35858234763145447\n",
            "558 0.3600350320339203\n",
            "559 0.3631145656108856\n",
            "560 0.3632729649543762\n",
            "561 0.36469772458076477\n",
            "562 0.3628053367137909\n",
            "563 0.36215174198150635\n",
            "564 0.35872167348861694\n",
            "565 0.35699400305747986\n",
            "566 0.35341739654541016\n",
            "567 0.3516847491264343\n",
            "568 0.34881043434143066\n",
            "569 0.34753772616386414\n",
            "570 0.34542110562324524\n",
            "571 0.3446146845817566\n",
            "572 0.34311702847480774\n",
            "573 0.34269455075263977\n",
            "574 0.34164202213287354\n",
            "575 0.3415340483188629\n",
            "576 0.3407180905342102\n",
            "577 0.34089693427085876\n",
            "578 0.34021297097206116\n",
            "579 0.3405826985836029\n",
            "580 0.3399077355861664\n",
            "581 0.34044018387794495\n",
            "582 0.3396720290184021\n",
            "583 0.3402845859527588\n",
            "584 0.33943021297454834\n",
            "585 0.34003740549087524\n",
            "586 0.3390991985797882\n",
            "587 0.33977359533309937\n",
            "588 0.33876004815101624\n",
            "589 0.3394261598587036\n",
            "590 0.3384060263633728\n",
            "591 0.33909475803375244\n",
            "592 0.338108628988266\n",
            "593 0.33882468938827515\n",
            "594 0.33790215849876404\n",
            "595 0.33865034580230713\n",
            "596 0.3377702534198761\n",
            "597 0.33857637643814087\n",
            "598 0.3377029597759247\n",
            "599 0.3385249376296997\n",
            "600 0.3376882076263428\n",
            "601 0.33854663372039795\n",
            "602 0.33770906925201416\n",
            "603 0.33854663372039795\n",
            "604 0.3377000391483307\n",
            "605 0.33851656317710876\n",
            "606 0.337660014629364\n",
            "607 0.3384261131286621\n",
            "608 0.3375714123249054\n",
            "609 0.3382974863052368\n",
            "610 0.33747124671936035\n",
            "611 0.3381495177745819\n",
            "612 0.3373846709728241\n",
            "613 0.338039755821228\n",
            "614 0.3373228907585144\n",
            "615 0.3379755914211273\n",
            "616 0.33728867769241333\n",
            "617 0.3379300832748413\n",
            "618 0.3372539281845093\n",
            "619 0.33786797523498535\n",
            "620 0.3371892273426056\n",
            "621 0.33776700496673584\n",
            "622 0.337119460105896\n",
            "623 0.33769115805625916\n",
            "624 0.33703160285949707\n",
            "625 0.33755946159362793\n",
            "626 0.3369063436985016\n",
            "627 0.3374040126800537\n",
            "628 0.3367731273174286\n",
            "629 0.3372555673122406\n",
            "630 0.3366650342941284\n",
            "631 0.3371407091617584\n",
            "632 0.3365626335144043\n",
            "633 0.33702436089515686\n",
            "634 0.33644041419029236\n",
            "635 0.3368864953517914\n",
            "636 0.3363160192966461\n",
            "637 0.33675554394721985\n",
            "638 0.3362034559249878\n",
            "639 0.3366309702396393\n",
            "640 0.3361091911792755\n",
            "641 0.3365649878978729\n",
            "642 0.336026668548584\n",
            "643 0.33649545907974243\n",
            "644 0.3359460234642029\n",
            "645 0.3364202380180359\n",
            "646 0.33585068583488464\n",
            "647 0.33631816506385803\n",
            "648 0.33573266863822937\n",
            "649 0.33617931604385376\n",
            "650 0.3355961740016937\n",
            "651 0.33603426814079285\n",
            "652 0.33545055985450745\n",
            "653 0.33589237928390503\n",
            "654 0.33530479669570923\n",
            "655 0.3357473611831665\n",
            "656 0.33515480160713196\n",
            "657 0.3356008529663086\n",
            "658 0.3350054919719696\n",
            "659 0.33545488119125366\n",
            "660 0.3348506689071655\n",
            "661 0.3352932631969452\n",
            "662 0.3346928060054779\n",
            "663 0.33512255549430847\n",
            "664 0.33454129099845886\n",
            "665 0.33497384190559387\n",
            "666 0.334392786026001\n",
            "667 0.3348400592803955\n",
            "668 0.33428820967674255\n",
            "669 0.3347533941268921\n",
            "670 0.33419519662857056\n",
            "671 0.3346910774707794\n",
            "672 0.3341091573238373\n",
            "673 0.33462420105934143\n",
            "674 0.3340167701244354\n",
            "675 0.33454105257987976\n",
            "676 0.33390551805496216\n",
            "677 0.3344290554523468\n",
            "678 0.3337780833244324\n",
            "679 0.334299236536026\n",
            "680 0.33364343643188477\n",
            "681 0.3341590464115143\n",
            "682 0.33352476358413696\n",
            "683 0.33405372500419617\n",
            "684 0.3334209620952606\n",
            "685 0.3339451551437378\n",
            "686 0.3333408534526825\n",
            "687 0.33388930559158325\n",
            "688 0.33330655097961426\n",
            "689 0.33390557765960693\n",
            "690 0.33331024646759033\n",
            "691 0.33393537998199463\n",
            "692 0.3333264887332916\n",
            "693 0.33396100997924805\n",
            "694 0.3333336412906647\n",
            "695 0.33397650718688965\n",
            "696 0.33335068821907043\n",
            "697 0.3339986801147461\n",
            "698 0.3333970606327057\n",
            "699 0.33407536149024963\n",
            "700 0.33350852131843567\n",
            "701 0.33417418599128723\n",
            "702 0.33368048071861267\n",
            "703 0.33439624309539795\n",
            "704 0.3339887261390686\n",
            "705 0.3347702920436859\n",
            "706 0.33446288108825684\n",
            "707 0.33534061908721924\n",
            "708 0.3351392149925232\n",
            "709 0.33611777424812317\n",
            "710 0.3360476493835449\n",
            "711 0.3371945023536682\n",
            "712 0.33731260895729065\n",
            "713 0.33864954113960266\n",
            "714 0.33897829055786133\n",
            "715 0.3405660092830658\n",
            "716 0.34108966588974\n",
            "717 0.34285569190979004\n",
            "718 0.3434332311153412\n",
            "719 0.3452719748020172\n",
            "720 0.3456345796585083\n",
            "721 0.3473552167415619\n",
            "722 0.34727224707603455\n",
            "723 0.34856176376342773\n",
            "724 0.34784603118896484\n",
            "725 0.3484158515930176\n",
            "726 0.34698352217674255\n",
            "727 0.3469635844230652\n",
            "728 0.34511858224868774\n",
            "729 0.3447001278400421\n",
            "730 0.3428097665309906\n",
            "731 0.34223154187202454\n",
            "732 0.3405693471431732\n",
            "733 0.3400055468082428\n",
            "734 0.33863019943237305\n",
            "735 0.33823099732398987\n",
            "736 0.3371025025844574\n",
            "737 0.3368474245071411\n",
            "738 0.33591824769973755\n",
            "739 0.335769921541214\n",
            "740 0.3349888026714325\n",
            "741 0.33501097559928894\n",
            "742 0.33433467149734497\n",
            "743 0.3344824016094208\n",
            "744 0.3338392674922943\n",
            "745 0.3340730369091034\n",
            "746 0.33347174525260925\n",
            "747 0.33380189538002014\n",
            "748 0.3331620395183563\n",
            "749 0.3335547149181366\n",
            "750 0.33283984661102295\n",
            "751 0.3332706093788147\n",
            "752 0.3325293958187103\n",
            "753 0.3330012261867523\n",
            "754 0.33224618434906006\n",
            "755 0.3327515721321106\n",
            "756 0.33199453353881836\n",
            "757 0.3325609862804413\n",
            "758 0.331771582365036\n",
            "759 0.332378089427948\n",
            "760 0.3315621614456177\n",
            "761 0.33219802379608154\n",
            "762 0.33135396242141724\n",
            "763 0.3320158123970032\n",
            "764 0.33117011189460754\n",
            "765 0.3318355679512024\n",
            "766 0.33100250363349915\n",
            "767 0.3316635489463806\n",
            "768 0.33083370327949524\n",
            "769 0.3315156400203705\n",
            "770 0.3307134211063385\n",
            "771 0.3314230144023895\n",
            "772 0.3306484520435333\n",
            "773 0.3313920497894287\n",
            "774 0.3306151330471039\n",
            "775 0.3313504755496979\n",
            "776 0.33056873083114624\n",
            "777 0.3313084840774536\n",
            "778 0.3305431008338928\n",
            "779 0.3312873840332031\n",
            "780 0.3305225372314453\n",
            "781 0.33126747608184814\n",
            "782 0.33051028847694397\n",
            "783 0.3312489986419678\n",
            "784 0.330493301153183\n",
            "785 0.33121174573898315\n",
            "786 0.33046576380729675\n",
            "787 0.33116602897644043\n",
            "788 0.33041882514953613\n",
            "789 0.33108946681022644\n",
            "790 0.330332487821579\n",
            "791 0.3309663236141205\n",
            "792 0.3302253186702728\n",
            "793 0.33082085847854614\n",
            "794 0.33013617992401123\n",
            "795 0.3307124674320221\n",
            "796 0.33004045486450195\n",
            "797 0.33061280846595764\n",
            "798 0.3299177587032318\n",
            "799 0.33044615387916565\n",
            "800 0.3297913670539856\n",
            "801 0.3302980363368988\n",
            "802 0.3296688497066498\n",
            "803 0.3301595449447632\n",
            "804 0.3295462131500244\n",
            "805 0.330019474029541\n",
            "806 0.32942506670951843\n",
            "807 0.32988426089286804\n",
            "808 0.3293209373950958\n",
            "809 0.32978883385658264\n",
            "810 0.32922160625457764\n",
            "811 0.3296857476234436\n",
            "812 0.3291217088699341\n",
            "813 0.32957154512405396\n",
            "814 0.32901301980018616\n",
            "815 0.329446017742157\n",
            "816 0.32889658212661743\n",
            "817 0.3293250799179077\n",
            "818 0.32877475023269653\n",
            "819 0.3291914165019989\n",
            "820 0.3286575376987457\n",
            "821 0.3290767967700958\n",
            "822 0.32853418588638306\n",
            "823 0.32893913984298706\n",
            "824 0.32839176058769226\n",
            "825 0.3287957012653351\n",
            "826 0.3282472789287567\n",
            "827 0.3286556601524353\n",
            "828 0.32809412479400635\n",
            "829 0.32851341366767883\n",
            "830 0.3279567062854767\n",
            "831 0.3283877372741699\n",
            "832 0.32782819867134094\n",
            "833 0.3282841742038727\n",
            "834 0.3276987373828888\n",
            "835 0.3281596601009369\n",
            "836 0.3275611996650696\n",
            "837 0.328032910823822\n",
            "838 0.3274390995502472\n",
            "839 0.3279304802417755\n",
            "840 0.3273497223854065\n",
            "841 0.32786235213279724\n",
            "842 0.32727041840553284\n",
            "843 0.327806293964386\n",
            "844 0.3271981179714203\n",
            "845 0.3277472257614136\n",
            "846 0.32711291313171387\n",
            "847 0.3276744782924652\n",
            "848 0.3270525336265564\n",
            "849 0.32763761281967163\n",
            "850 0.3270254135131836\n",
            "851 0.32764071226119995\n",
            "852 0.32701390981674194\n",
            "853 0.3276432156562805\n",
            "854 0.32702943682670593\n",
            "855 0.32769668102264404\n",
            "856 0.3271145522594452\n",
            "857 0.32782697677612305\n",
            "858 0.3272661864757538\n",
            "859 0.32803359627723694\n",
            "860 0.32746419310569763\n",
            "861 0.32826024293899536\n",
            "862 0.32775184512138367\n",
            "863 0.32860222458839417\n",
            "864 0.32818952202796936\n",
            "865 0.32914116978645325\n",
            "866 0.3288012444972992\n",
            "867 0.3298286199569702\n",
            "868 0.3296513557434082\n",
            "869 0.33080270886421204\n",
            "870 0.330791711807251\n",
            "871 0.3321341574192047\n",
            "872 0.33229705691337585\n",
            "873 0.33380675315856934\n",
            "874 0.3340725302696228\n",
            "875 0.33567118644714355\n",
            "876 0.3359140157699585\n",
            "877 0.3376554548740387\n",
            "878 0.3377215564250946\n",
            "879 0.3393506407737732\n",
            "880 0.33906376361846924\n",
            "881 0.3403905928134918\n",
            "882 0.33956873416900635\n",
            "883 0.3404027819633484\n",
            "884 0.33913931250572205\n",
            "885 0.33950597047805786\n",
            "886 0.3379175662994385\n",
            "887 0.3379196524620056\n",
            "888 0.3362862467765808\n",
            "889 0.33606579899787903\n",
            "890 0.334527850151062\n",
            "891 0.33427006006240845\n",
            "892 0.33291032910346985\n",
            "893 0.33267074823379517\n",
            "894 0.33147868514060974\n",
            "895 0.3313177227973938\n",
            "896 0.33032917976379395\n",
            "897 0.330270379781723\n",
            "898 0.329422265291214\n",
            "899 0.3294481337070465\n",
            "900 0.32872503995895386\n",
            "901 0.3288235366344452\n",
            "902 0.32821065187454224\n",
            "903 0.32842564582824707\n",
            "904 0.327878475189209\n",
            "905 0.3282093405723572\n",
            "906 0.327665776014328\n",
            "907 0.3281024396419525\n",
            "908 0.3275025188922882\n",
            "909 0.32802173495292664\n",
            "910 0.32728397846221924\n",
            "911 0.32778412103652954\n",
            "912 0.32692086696624756\n",
            "913 0.3273482322692871\n",
            "914 0.3264516592025757\n",
            "915 0.3268679976463318\n",
            "916 0.3260017931461334\n",
            "917 0.3264102339744568\n",
            "918 0.32558929920196533\n",
            "919 0.32601043581962585\n",
            "920 0.3252405822277069\n",
            "921 0.32570505142211914\n",
            "922 0.3249804675579071\n",
            "923 0.32548218965530396\n",
            "924 0.32478097081184387\n",
            "925 0.3253525197505951\n",
            "926 0.32463523745536804\n",
            "927 0.32527387142181396\n",
            "928 0.32457518577575684\n",
            "929 0.32527124881744385\n",
            "930 0.3245384097099304\n",
            "931 0.3252839148044586\n",
            "932 0.32450947165489197\n",
            "933 0.3252880871295929\n",
            "934 0.3244978189468384\n",
            "935 0.3253023028373718\n",
            "936 0.3244462013244629\n",
            "937 0.32526689767837524\n",
            "938 0.3243620991706848\n",
            "939 0.3251682221889496\n",
            "940 0.3242570459842682\n",
            "941 0.32504788041114807\n",
            "942 0.3241786062717438\n",
            "943 0.32497522234916687\n",
            "944 0.3241250813007355\n",
            "945 0.3249344527721405\n",
            "946 0.32411789894104004\n",
            "947 0.32492560148239136\n",
            "948 0.324150949716568\n",
            "949 0.3249724805355072\n",
            "950 0.32422104477882385\n",
            "951 0.3250691294670105\n",
            "952 0.32435619831085205\n",
            "953 0.32521703839302063\n",
            "954 0.32450178265571594\n",
            "955 0.32534879446029663\n",
            "956 0.32464686036109924\n",
            "957 0.32545575499534607\n",
            "958 0.32471901178359985\n",
            "959 0.3254573345184326\n",
            "960 0.32473891973495483\n",
            "961 0.3253883421421051\n",
            "962 0.3247303068637848\n",
            "963 0.3253161311149597\n",
            "964 0.324691504240036\n",
            "965 0.3251996338367462\n",
            "966 0.32464224100112915\n",
            "967 0.32508736848831177\n",
            "968 0.32461538910865784\n",
            "969 0.3250052034854889\n",
            "970 0.32460644841194153\n",
            "971 0.32494446635246277\n",
            "972 0.32460111379623413\n",
            "973 0.3249019980430603\n",
            "974 0.3246344029903412\n",
            "975 0.3248980939388275\n",
            "976 0.32469889521598816\n",
            "977 0.3249201476573944\n",
            "978 0.3247385323047638\n",
            "979 0.3249076008796692\n",
            "980 0.32475754618644714\n",
            "981 0.324882447719574\n",
            "982 0.32476258277893066\n",
            "983 0.32485663890838623\n",
            "984 0.3248167932033539\n",
            "985 0.3248802721500397\n",
            "986 0.3249080777168274\n",
            "987 0.3249422311782837\n",
            "988 0.3250572979450226\n",
            "989 0.32506173849105835\n",
            "990 0.32527491450309753\n",
            "991 0.32529255747795105\n",
            "992 0.32562196254730225\n",
            "993 0.3256703317165375\n",
            "994 0.3261669874191284\n",
            "995 0.3262537717819214\n",
            "996 0.3269292414188385\n",
            "997 0.3270532786846161\n",
            "998 0.3279387056827545\n",
            "999 0.3280578553676605\n"
          ]
        }
      ],
      "source": [
        "# Your code here\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "random_seed = np.random.seed(42)\n",
        "optimizer = torch.optim.SGD(model1.parameters(), lr=1.049)\n",
        "\n",
        "losses1 = []\n",
        "losses1_test = []\n",
        "\n",
        "for t in range(1000):                # 1000 iterations\n",
        "\n",
        "    # Forward pass: compute prediction on training set\n",
        "    y_pred_fin = model1(X_scaled_torch)\n",
        "\n",
        "    # Compute loss\n",
        "    loss = criterion(y_pred_fin, y_scaled_torch)\n",
        "    print(t, loss.item())\n",
        "    losses1.append(loss.item())\n",
        "    if torch.isnan(loss):\n",
        "        break\n",
        "\n",
        "    # Compute gradient\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "\n",
        "    # Update\n",
        "    optimizer.step()\n",
        "\n",
        "    # Compute loss on test set\n",
        "    losses1_test.append(criterion(model1(X_test), y_test).item())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Assume X_train and y_train are already defined and preprocessed\n",
        "# X_train = ... (your training feature matrix)\n",
        "# y_train = ... (your training label array)\n",
        "\n",
        "# Define the network dimensions\n",
        "D_in = X_scaled_torch.shape[1]  # Number of input features\n",
        "H1 = 150                 # Number of neurons in the hidden layer\n",
        "D_out = 3                # Number of output classes\n",
        "\n",
        "# Create an instance of the Net class\n",
        "model = Net(D_in, H1, D_out)\n",
        "\n",
        "# Define the optimizer and the loss function\n",
        "optimizer = optim.SGD(model.parameters(), lr=1.049)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(1000):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()               # Clear gradients for the next train\n",
        "    output = model(X_scaled_torch)             # Forward pass: compute the output class probabilities\n",
        "    loss = criterion(output, y_scaled_torch)   # Compute the loss: difference between the predicted and actual class\n",
        "    loss.backward()                     # Backward pass: compute the weight\n",
        "    optimizer.step()                    # Optimizer step: update the weights of neurons\n",
        "\n",
        "    if epoch % 100 == 0:\n",
        "        print(f'Epoch {epoch+1}/{1000}, Loss: {loss.item()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x2Ml-beX4aLv",
        "outputId": "bb0e179a-5fa3-4916-e841-5127027918e9"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000, Loss: 1.1188501119613647\n",
            "Epoch 101/1000, Loss: 0.4700949192047119\n",
            "Epoch 201/1000, Loss: 0.37704798579216003\n",
            "Epoch 301/1000, Loss: 0.3590754568576813\n",
            "Epoch 401/1000, Loss: 0.36542001366615295\n",
            "Epoch 501/1000, Loss: 0.3414454460144043\n",
            "Epoch 601/1000, Loss: 0.3376882076263428\n",
            "Epoch 701/1000, Loss: 0.33350852131843567\n",
            "Epoch 801/1000, Loss: 0.3297913670539856\n",
            "Epoch 901/1000, Loss: 0.32872503995895386\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediction\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    predictions = model(suspects_new_tensor)\n",
        "    predicted_classes = torch.argmax(predictions, dim=1)\n",
        "\n",
        "# Now `predicted_classes` holds the predicted classes for the new dataset\n",
        "\n",
        "# Convert the predicted classes tensor to a numpy array\n",
        "predicted_classes_np = predicted_classes.cpu().numpy()\n",
        "\n",
        "# Create a DataFrame from the numpy array\n",
        "predicted_df = pd.DataFrame(predicted_classes_np, columns=['Predicted_Class'])\n",
        "\n",
        "# Assuming you have another DataFrame `suspects_df` which contains the details of the suspects\n",
        "# Make sure that `suspects_df` has the same number of rows as `predicted_df`\n",
        "userID = suspects['userID']\n",
        "\n",
        "userID.index = predicted_df.index\n",
        "\n",
        "suspects_score = pd.concat([userID, predicted_df], axis = 1)\n",
        "\n",
        "# Now `suspects_df` contains a new column 'Predicted_Class' which has the predicted classes merged with other suspect details\n",
        "print(suspects_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3EuwJxGqBAdJ",
        "outputId": "25ed161a-0b93-4490-decc-3ee5d372ed48"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     userID  Predicted_Class\n",
            "0    317991                1\n",
            "1    241892                1\n",
            "2    303376                1\n",
            "3    761992                1\n",
            "4    373318                1\n",
            "..      ...              ...\n",
            "709  458293                2\n",
            "710  218415                2\n",
            "711  173906                2\n",
            "712  178685                0\n",
            "713  200865                0\n",
            "\n",
            "[714 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(suspects_score['Predicted_Class'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cEwB6r5rM6SY",
        "outputId": "e7a19cd2-8103-4017-e8a7-b0481cc70408"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted_Class\n",
            "2    291\n",
            "1    253\n",
            "0    170\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6hdN8ZOJMgQ"
      },
      "source": [
        "Display the table with two columns: 'userID' and the corresponding predicted Credit_Mix."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_classes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Z7uu9uYCG8T",
        "outputId": "ab00cf02-93e1-496c-e146-b4efd517db96"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1, 1, 1,\n",
              "        1, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 1, 2, 2, 0, 0, 0, 0, 1, 1,\n",
              "        1, 2, 2, 2, 0, 2, 2, 2, 0, 0, 0, 2, 2, 2, 2, 0, 0, 1, 1, 0, 2, 2, 2, 2,\n",
              "        2, 1, 2, 2, 2, 0, 0, 0, 1, 1, 2, 2, 1, 1, 1, 1, 2, 2, 2, 0, 0, 0, 2, 2,\n",
              "        2, 2, 2, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 2, 1, 2, 2,\n",
              "        2, 0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 1, 1, 2, 2, 2, 0, 0, 0, 2, 2, 2, 2, 0,\n",
              "        2, 0, 0, 2, 2, 1, 1, 1, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 0,\n",
              "        0, 0, 1, 1, 1, 1, 2, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 2, 2, 1, 1, 1, 1,\n",
              "        1, 0, 0, 0, 1, 1, 1, 1, 1, 2, 2, 2, 0, 0, 0, 0, 2, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 1, 1, 1, 2, 2, 2, 0, 0, 1, 1, 2,\n",
              "        2, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 2, 1, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 2,\n",
              "        2, 2, 2, 2, 2, 2, 1, 1, 1, 2, 2, 2, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 2, 2,\n",
              "        2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 1, 1, 2, 1, 1, 0, 0, 2,\n",
              "        2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 0, 2, 2, 2,\n",
              "        1, 1, 2, 2, 2, 0, 0, 1, 1, 1, 2, 2, 2, 2, 0, 0, 1, 1, 2, 2, 2, 2, 2, 2,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 2, 2, 2, 2, 0, 0, 0, 0, 0,\n",
              "        0, 0, 2, 2, 2, 2, 1, 1, 1, 0, 0, 0, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0,\n",
              "        0, 0, 2, 2, 2, 1, 1, 1, 1, 1, 1, 0, 0, 0, 2, 2, 1, 1, 2, 2, 1, 2, 2, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 2, 2, 2, 1, 2, 2, 0, 2, 0, 0, 0, 0, 1, 2,\n",
              "        2, 1, 1, 1, 1, 2, 1, 2, 1, 2, 1, 1, 1, 1, 1, 0, 0, 1, 1, 2, 2, 2, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 2, 2, 0, 0, 0, 2, 1, 1, 2, 0, 0, 0, 0, 2, 0, 0, 0,\n",
              "        1, 1, 1, 1, 1, 0, 0, 2, 2, 2, 2, 2, 0, 0, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0,\n",
              "        2, 2, 2, 1, 1, 1, 1, 1, 1, 2, 1, 2, 2, 2, 2, 1, 1, 1, 2, 2, 0, 0, 2, 2,\n",
              "        2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 0, 2, 2, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2,\n",
              "        2, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 1, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2,\n",
              "        2, 1, 1, 1, 1, 0, 2, 2, 2, 1, 1, 1, 1, 2, 2, 2, 1, 2, 1, 2, 2, 0, 0, 0,\n",
              "        0, 0, 2, 2, 2, 1, 1, 0, 0, 0, 0, 1, 1, 1, 2, 2, 2, 1, 1, 1, 2, 2, 2, 2,\n",
              "        1, 1, 1, 1, 1, 1, 0, 0, 2, 2, 0, 0, 0, 0, 2, 2, 2, 1, 1, 1, 1, 2, 1, 1,\n",
              "        1, 0, 2, 2, 0, 0, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 1, 1, 1, 1, 1, 0, 1,\n",
              "        1, 1, 2, 2, 2, 1, 1, 1, 0, 0, 0, 2, 2, 2, 2, 2, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fSbm5gtNADZ5",
        "outputId": "2a034721-ffdc-44a9-8017-e8201642c58d"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-5.5805,  3.8890,  1.9711],\n",
              "        [-6.0005,  4.0094,  2.2322],\n",
              "        [-5.9562,  4.0965,  2.0339],\n",
              "        ...,\n",
              "        [-0.5312, -3.8668,  4.4326],\n",
              "        [ 4.5020, -5.1333,  0.8979],\n",
              "        [ 5.9284, -8.4128,  2.5953]])"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "PeIKEtZ8JKS9",
        "outputId": "f37d6185-c7aa-4eea-d930-341ab1d17d16"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Predicted_Class\n",
              "0                  1\n",
              "1                  1\n",
              "2                  1\n",
              "3                  1\n",
              "4                  1\n",
              "..               ...\n",
              "709                2\n",
              "710                2\n",
              "711                2\n",
              "712                0\n",
              "713                0\n",
              "\n",
              "[714 rows x 1 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ddca419d-babd-43c1-9de3-56f3c0167a96\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Predicted_Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>709</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>710</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>711</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>712</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>713</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>714 rows × 1 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ddca419d-babd-43c1-9de3-56f3c0167a96')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ddca419d-babd-43c1-9de3-56f3c0167a96 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ddca419d-babd-43c1-9de3-56f3c0167a96');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-39b72d84-81d8-4cb5-a9bb-976940ae00b6\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-39b72d84-81d8-4cb5-a9bb-976940ae00b6')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-39b72d84-81d8-4cb5-a9bb-976940ae00b6 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "predicted_df",
              "summary": "{\n  \"name\": \"predicted_df\",\n  \"rows\": 714,\n  \"fields\": [\n    {\n      \"column\": \"Predicted_Class\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1,\n          2,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 57
        }
      ],
      "source": [
        "#Your code here\n",
        "predicted_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4oGVP1hJaCZ"
      },
      "source": [
        "As mentioned in the beginning, we have reasons to believe that the suspect had a very good credit score. But we must make no errors, because a lot is at stake. We must be consident in our predictions.\n",
        "\n",
        "Therefore, we need to analyze not just the predicted category but also how certain the model is about each prediction. Display the probabilities of observations in the 'suspects' dataset falling within the given classes.\n",
        "\n",
        "_Hint: you can display the probabilities simply as a dataframe, but for better overview you can use visualization tools_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fSL2d1K-KeKW",
        "outputId": "f330da1f-561e-4e97-a9de-ec320dab621b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     userID Predicted_Credit_Score  Probability\n",
            "0    317991                   Good     0.871848\n",
            "1    241892                   Good     0.855316\n",
            "2    303376                   Good     0.887179\n",
            "3    761992                   Good     0.912380\n",
            "4    373318                   Good     0.890139\n",
            "..      ...                    ...          ...\n",
            "709  458293               Standard     0.913451\n",
            "710  218415               Standard     0.994114\n",
            "711  173906               Standard     0.992817\n",
            "712  178685                    Bad     0.973447\n",
            "713  200865                    Bad     0.965547\n",
            "\n",
            "[714 rows x 3 columns]\n"
          ]
        }
      ],
      "source": [
        "# Your code here\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "# Assuming model and suspects_new_tensor are already defined and loaded\n",
        "\n",
        "# Evaluation mode and prediction\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    probabilities = torch.softmax(model(suspects_new_tensor), dim=1)  # Get class probabilities\n",
        "    predicted_classes = torch.argmax(probabilities, dim=1)  # Get predicted class index\n",
        "\n",
        "# Convert the predicted classes tensor to a numpy array\n",
        "predicted_classes_np = predicted_classes.cpu().numpy()\n",
        "\n",
        "# Decode the predicted classes using the inverse of label encoding\n",
        "# Assuming 'le' is your LabelEncoder instance\n",
        "decoded_classes = le.inverse_transform(predicted_classes_np)\n",
        "\n",
        "# Create a DataFrame with decoded classes\n",
        "predicted_df = pd.DataFrame({\n",
        "    'Predicted_Credit_Score': decoded_classes,\n",
        "    'Probability': probabilities.max(dim=1).values.cpu().numpy()  # Get max probability for each prediction\n",
        "})\n",
        "\n",
        "# Assuming 'suspects' DataFrame contains 'userID'\n",
        "# Make sure that 'suspects_df' has the same number of rows as 'predicted_df'\n",
        "userID = suspects['userID']\n",
        "userID.reset_index(drop=True, inplace=True)  # Reset index to align with predicted_df\n",
        "\n",
        "# Concatenate userID with the predictions and probabilities\n",
        "suspects_score = pd.concat([userID, predicted_df], axis=1)\n",
        "\n",
        "# Print the final DataFrame\n",
        "print(suspects_score)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_ids_search = [200865, 761992, 858566, 862880, 526987]\n",
        "\n",
        "# Assuming 'Good' and 'Excellent' are considered good credit scores\n",
        "good_scores = ['Good']\n",
        "\n",
        "# Filter the DataFrame for these user IDs and good credit scores\n",
        "filtered_df = suspects_score[(suspects_score['userID'].isin(user_ids_search)) & (suspects_score['Predicted_Credit_Score'].isin(good_scores))]\n",
        "\n",
        "# Print the filtered DataFrame\n",
        "print(filtered_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7FlVLeIj-0oc",
        "outputId": "65fc68a4-77d0-4d4d-dc4a-cc34c08feaa6"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     userID Predicted_Credit_Score  Probability\n",
            "3    761992                   Good     0.912380\n",
            "636  526987                   Good     0.927306\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OK0J3mmALxUo"
      },
      "source": [
        "*Question 3:*\n",
        "\n",
        "**Which of the following suspects have a good credit mix according to your model's predictions?**\n",
        "\n",
        "\n",
        "*   200865\n",
        "*   761992\n",
        "*   858566\n",
        "*   862880\n",
        "*   526987\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}